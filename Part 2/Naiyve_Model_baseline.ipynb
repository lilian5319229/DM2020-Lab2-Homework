{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import KeyedVectors\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Embedding\n",
    "from keras.layers import ReLU, Softmax, Dropout\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file=list()\n",
    "data=list()\n",
    "\n",
    "#read json file\n",
    "with open('tweets_DM.json','r')as file:\n",
    "    for line in file:\n",
    "        json_file.append(json.loads(line))\n",
    "        \n",
    "#processing the data in json file\n",
    "for line in json_file:\n",
    "    tweet_id=line['_source']['tweet']['tweet_id']\n",
    "    text=line['_source']['tweet']['text']\n",
    "    hashtags=line['_source']['tweet']['hashtags']\n",
    "    data.append([tweet_id,text,hashtags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>[Snapchat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>[bibleverse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "3  0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
       "4  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "\n",
       "                        hashtags  \n",
       "0                     [Snapchat]  \n",
       "1  [freepress, TrumpLegacy, CNN]  \n",
       "2                   [bibleverse]  \n",
       "3                             []  \n",
       "4                             []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame(data,columns=['tweet_id','text','hashtags'])\n",
    "data_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read emotion.csv\n",
    "emo_df=pd.read_csv('emotion.csv')\n",
    "\n",
    "#read data_identification.csv\n",
    "id_df=pd.read_csv('data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tweet_id                                               text  \\\n",
      "0       0x28b412  Confident of your obedience, I write to you, k...   \n",
      "1       0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
      "2       0x218443  When do you have enough ? When are you satisfi...   \n",
      "3       0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n",
      "4       0x26289a  In these tough times, who do YOU turn to as yo...   \n",
      "...          ...                                                ...   \n",
      "411967  0x2913b4  \"For this is the message that ye heard from th...   \n",
      "411968  0x2a980e  \"There is a lad here, which hath five barley l...   \n",
      "411969  0x316b80  When you buy the last 2 tickets remaining for ...   \n",
      "411970  0x29d0cb  I swear all this hard work gone pay off one da...   \n",
      "411971  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n",
      "\n",
      "                                 hashtags identification  \n",
      "0                            [bibleverse]           test  \n",
      "1                                      []           test  \n",
      "2       [materialism, money, possessions]           test  \n",
      "3                    [GodsPlan, GodsWork]           test  \n",
      "4                                      []           test  \n",
      "...                                   ...            ...  \n",
      "411967                                 []           test  \n",
      "411968                                 []           test  \n",
      "411969    [mixedfeeling, butimTHATperson]           test  \n",
      "411970                                 []           test  \n",
      "411971                                 []           test  \n",
      "\n",
      "[411972 rows x 4 columns]\n",
      "         tweet_id                                               text  \\\n",
      "0        0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
      "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
      "2        0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
      "3        0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
      "4        0x2c91a8       Still waiting on those supplies Liscus. <LH>   \n",
      "...           ...                                                ...   \n",
      "1455558  0x321566  I'm SO HAPPY!!! #NoWonder the name of this sho...   \n",
      "1455559  0x38959e  In every circumtance I'd like to be thankful t...   \n",
      "1455560  0x2cbca6  there's currently two girls walking around the...   \n",
      "1455561  0x24faed  Ah, corporate life, where you can date <LH> us...   \n",
      "1455562  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n",
      "\n",
      "                              hashtags       emotion  \n",
      "0                           [Snapchat]  anticipation  \n",
      "1        [freepress, TrumpLegacy, CNN]       sadness  \n",
      "2                                   []          fear  \n",
      "3            [authentic, LaughOutLoud]           joy  \n",
      "4                                   []  anticipation  \n",
      "...                                ...           ...  \n",
      "1455558              [NoWonder, Happy]           joy  \n",
      "1455559                             []           joy  \n",
      "1455560                     [blessyou]           joy  \n",
      "1455561                             []           joy  \n",
      "1455562                  [Sundayvibes]           joy  \n",
      "\n",
      "[1455563 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#spilt test and train data\n",
    "test_df_1=id_df[id_df['identification']=='test']\n",
    "\n",
    "public_test_df=data_df.merge(test_df_1,left_on='tweet_id', right_on='tweet_id')\n",
    "print(public_test_df)\n",
    "\n",
    "train_df=data_df.merge(emo_df,left_on='tweet_id', right_on='tweet_id')\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preprocess(df):\n",
    "    # remove <LH> text\n",
    "    df['text'] = df['text'].apply(lambda s : s.replace('<LH>',''))    \n",
    "    df['tmp'] = df['text'].apply(lambda s : tweet_tokenizer.tokenize(s))\n",
    "\n",
    "    df['p_text'] = df['tmp'].apply(lambda a : ' '.join(a))\n",
    "    df.drop(['tmp'], axis=1, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>emotion</th>\n",
       "      <th>p_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>People who post \" add me on #Snapchat \" must b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>sadness</td>\n",
       "      <td>useruser As we see , Trump is dangerous to #fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚</td>\n",
       "      <td>[]</td>\n",
       "      <td>fear</td>\n",
       "      <td>Now ISSA is stalking Tasha face with tears of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>joy</td>\n",
       "      <td>useruser useruser Thx for the BEST TIME tonigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus.</td>\n",
       "      <td>[]</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>Still waiting on those supplies Liscus .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2  0x1cd5b0                    Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚    \n",
       "3  0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
       "4  0x2c91a8           Still waiting on those supplies Liscus.    \n",
       "\n",
       "                        hashtags       emotion  \\\n",
       "0                     [Snapchat]  anticipation   \n",
       "1  [freepress, TrumpLegacy, CNN]       sadness   \n",
       "2                             []          fear   \n",
       "3      [authentic, LaughOutLoud]           joy   \n",
       "4                             []  anticipation   \n",
       "\n",
       "                                              p_text  \n",
       "0  People who post \" add me on #Snapchat \" must b...  \n",
       "1  useruser As we see , Trump is dangerous to #fr...  \n",
       "2  Now ISSA is stalking Tasha face with tears of ...  \n",
       "3  useruser useruser Thx for the BEST TIME tonigh...  \n",
       "4           Still waiting on those supplies Liscus .  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocess(train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>identification</th>\n",
       "      <th>p_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>test</td>\n",
       "      <td>Confident of your obedience , I write to you ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>test</td>\n",
       "      <td>\" Trust is not the same as faith . A friend is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>test</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>test</td>\n",
       "      <td>God woke you up , now chase the day #GodsPlan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>test</td>\n",
       "      <td>In these tough times , who do YOU turn to as y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  \\\n",
       "0  0x28b412  Confident of your obedience, I write to you, k...   \n",
       "1  0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "2  0x218443  When do you have enough ? When are you satisfi...   \n",
       "3  0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n",
       "4  0x26289a  In these tough times, who do YOU turn to as yo...   \n",
       "\n",
       "                            hashtags identification  \\\n",
       "0                       [bibleverse]           test   \n",
       "1                                 []           test   \n",
       "2  [materialism, money, possessions]           test   \n",
       "3               [GodsPlan, GodsWork]           test   \n",
       "4                                 []           test   \n",
       "\n",
       "                                              p_text  \n",
       "0  Confident of your obedience , I write to you ,...  \n",
       "1  \" Trust is not the same as faith . A friend is...  \n",
       "2  When do you have enough ? When are you satisfi...  \n",
       "3  God woke you up , now chase the day #GodsPlan ...  \n",
       "4  In these tough times , who do YOU turn to as y...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocess(public_test_df)\n",
    "public_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list=train_df['p_text']\n",
    "y_list=train_df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1164450 1164450\n",
      "291113 291113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x_list, y_list, test_size=0.2, random_state=42)\n",
    "print(len(train_x), len(train_y))\n",
    "print(len(test_x), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    p_text  emotion\n",
      "834097   For those of you who have followed me , thanks...      joy\n",
      "355739   When you have to take a day off from work in o...  sadness\n",
      "625638   Wherever you are ; be all there . That â€™ s how...      joy\n",
      "678647   useruser Would be nice for all the PSA players...      joy\n",
      "441397   69 The moments in your life are only once #Lif...    trust\n",
      "...                                                    ...      ...\n",
      "259178   And above all these things put on charity , wh...      joy\n",
      "1414414  useruser Still a devastating poll for Trump .....  sadness\n",
      "131932                             useruser Ohhh , tears !      joy\n",
      "671155   Sponsor shirts are completed and Spirit Gear h...      joy\n",
      "121958   Their behavior is due to a lack of love . We n...      joy\n",
      "\n",
      "[1164450 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "c={\"p_text\" : train_x,\n",
    "   \"emotion\" : train_y}\n",
    "train_df1=pd.DataFrame(c)\n",
    "print(train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    p_text   emotion\n",
      "970345   Been a #week now #since I my #Mom . I #miss he...  surprise\n",
      "1145883  Follow our Librarian , Ms . Bird bird for more...       joy\n",
      "468264   Wonder if the guys who skate in Foxboro over t...       joy\n",
      "949718   useruser Bloody puts it mildly , will be posti...       joy\n",
      "982592   Beat the Dolphins next week and we are back to...       joy\n",
      "...                                                    ...       ...\n",
      "752756   Cars in the shop and apparently wings and beer...     trust\n",
      "1096194  I have been awake since just before 5am . Babi...       joy\n",
      "105639   I worked hard to save the situation but it fai...   sadness\n",
      "842760   and must bear and kept spontaneously Always no...       joy\n",
      "1425856                                Nobody texting back   disgust\n",
      "\n",
      "[291113 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "d={\"p_text\" : test_x,\n",
    "   \"emotion\" : test_y}\n",
    "test_df1=pd.DataFrame(d)\n",
    "print(test_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 : Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \"Naive bayes\" classifier as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 50000\n",
    "df = train_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 292.5648500919342 sec\n",
      "(1164450, 50000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "BOW = CountVectorizer(max_features=MAX_FEATURES, \n",
    "                             tokenizer=nltk.word_tokenize, \n",
    "                             ngram_range=(1,2))\n",
    "\n",
    "BOW_f = BOW.fit_transform(df['p_text'])\n",
    "\n",
    "print(f'time : {time.time() - start} sec')\n",
    "print(BOW_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43761596620999355\n",
      "time : 48.38650584220886 sec\n"
     ]
    }
   ],
   "source": [
    "# cross value score on naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "X = BOW_f\n",
    "y = df['emotion']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "print(cross_val_score(clf, X, y, cv=10, scoring='f1_macro').mean())\n",
    "print(f'time : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)\n",
    "X_private_test = BOW.transform(test_df1['p_text'])\n",
    "y_pred = clf.predict(X_private_test)\n",
    "y_true = test_df1['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.32      0.33      0.33      7946\n",
      "anticipation       0.59      0.54      0.56     49984\n",
      "     disgust       0.35      0.55      0.43     27669\n",
      "        fear       0.32      0.49      0.38     12846\n",
      "         joy       0.69      0.52      0.59    102943\n",
      "     sadness       0.40      0.50      0.45     38745\n",
      "    surprise       0.32      0.29      0.30      9816\n",
      "       trust       0.45      0.43      0.44     41164\n",
      "\n",
      "    accuracy                           0.50    291113\n",
      "   macro avg       0.43      0.46      0.44    291113\n",
      "weighted avg       0.53      0.50      0.51    291113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use navie bayas as baseline\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'sadness', 'fear', 'trust'], dtype='<U12')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on public_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_private_test1 = BOW.transform(public_test_df['p_text'])\n",
    "y_pred1 = clf.predict(X_private_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test_df['predict'] = y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = public_test_df[['tweet_id', 'predict']]\n",
    "output_df = output_df.rename(columns={'tweet_id':'id', 'predict':'emotion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('Naiyve.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
